# 实战：抽取式问答
- 目的： 微调一个 BERT 模型来完成抽取式问答任务：对于给定的问题，从上下文中抽取出概率最大的文本片段作为答案。
- 数据集：中文阅读理解语料库 CMRC 2018 作为数据集，该语料是一个类似于 SQuAD 的抽取式数据集，对于每个问题都从原文中截取片段 (span) 作为答案：

比如：{"context": "《战国无双3》（）是由光荣和ω-force开发的战国无双系列的正统第三续作。本作以三大故事为主轴，分别是以武田信玄等人为主的《关东三国志》，织田信长等人为主的《战国三杰》，石田三成等人为主的《关原的年轻武者》，丰富游戏内的剧情。此部份专门介绍角色，欲知武器情报、奥义字或擅长攻击类型等，请至战国无双系列1.由于乡里大辅先生因故去世，不得不寻找其他声优接手。从猛将传 and Z开始。2.战国无双 编年史的原创男女主角亦有专属声优。此模式是任天堂游戏谜之村雨城改编的新增模式。...", 
 "qas": [{
     "question": "《战国无双3》是由哪两个公司合作开发的？", 
     "id": "DEV_0_QUERY_0", 
     "answers": [{
         "text": "光荣和ω-force", 
         "answer_start": 11
     }, {
         "text": "光荣和ω-force", 
         "answer_start": 11
     }, {
         "text": "光荣和ω-force", 
         "answer_start": 11
     }]
 }

### 细节：
- 一个问题可能对应有多个参考答案，所以对于answer是一个列表
    - 在训练时我们任意选择其中一个作为标签
    - 在验证/测试时，我们则将预测答案和所有参考答案都送入打分函数来评估模型的性能。

- 标签是答案在上下文中起始/结束 token 的索引，模型的任务就是预测每个 token 为答案片段的起始/结束的概率，
    - 即为每个 token 预测一个起始 logit 值和结束 logit 值。

    ![image.png](attachment:image.png)
    - 所以数据预处理时候，需要根据 offset_mapping 来将原始的字符级别的答案映射到 token 级别的索引。
    - 还需要手动地将答案文本的在原文中的起始/结束位置映射到每个块的 token 索引，以构建答案标签 start_positions 和 end_positions。
